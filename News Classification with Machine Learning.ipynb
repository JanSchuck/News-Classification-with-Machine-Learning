{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a44b7c-607d-4de0-92fb-36600d7ae3cc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0044fd89-8bdb-41fc-9f9a-ee28038fa2a1",
   "metadata": {},
   "source": [
    "This notebook is a shortened version of a notebook that I wanted to use in my bachelor thesis.\n",
    "Unfortunately I don't need the machine learning model anymore but I still wanted to share this approach..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ff3a9-9974-466f-83dc-d8a98a67be04",
   "metadata": {},
   "source": [
    "I achieved an accuracy of around 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d8564",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07e2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa51ae0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c25f07b7-4350-4829-9333-1481e6fa41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "News_Titles_df = pd.read_csv(\"/Users/jan/Documents/Python_Projects/Mashine_Learning_Categories/News_Titles_Examples.csv\", index_col=None, header=0)\n",
    "\n",
    "News_Titles_df = News_Titles_df.drop_duplicates(subset=\"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29f652",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd7322a-c72b-41e0-bb9c-a185804f1ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16147 entries, 0 to 16146\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Title      16147 non-null  object\n",
      " 1   URL        16147 non-null  object\n",
      " 2   Date_Info  16147 non-null  object\n",
      " 3   News_page  16147 non-null  object\n",
      " 4   Category   16147 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 756.9+ KB\n"
     ]
    }
   ],
   "source": [
    "News_Titles_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff17c717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ausland         3608\n",
       "Panorama        3116\n",
       "Politik         2377\n",
       "Wirtschaft      2112\n",
       "Sport           1975\n",
       "Wissenschaft    1365\n",
       "Kultur          1074\n",
       "Netzwelt         520\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News_Titles_df[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5811b6",
   "metadata": {},
   "source": [
    "# Encoding titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea0e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "titel_set = News_Titles_df[[\"Title\",\"Category\"]]\n",
    "title_set_copy = titel_set.copy()\n",
    "encoded_titel_set = Encoder(title_set_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c4486",
   "metadata": {},
   "source": [
    "# Testing for best machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "046b5c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.221259 (0.001688)\n",
      "KNN: 0.432453 (0.006735)\n",
      "CART: 0.413099 (0.013943)\n",
      "NB: 0.219866 (0.002837)\n"
     ]
    }
   ],
   "source": [
    "# Split-out validation dataset\n",
    "dataset = encoded_titel_set\n",
    "array = dataset.values\n",
    "X = array[:,0]\n",
    "y = array[:,1]\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train=X_train.reshape(-1, 1)\n",
    "X_validation=X_validation.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9d2a4",
   "metadata": {},
   "source": [
    "# Testing Multinomial Naive Bayes algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "342344b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7027863777089783\n",
      "[[649   1   0  43  22   7   8   8]\n",
      " [ 52  87   0  32  23  17  10   3]\n",
      " [ 23   2  16  18  18   3  18   2]\n",
      " [ 87   4   2 452  45  10  17   5]\n",
      " [ 84   1   0  34 324   4  13   8]\n",
      " [ 21   2   0  21   4 355   3   1]\n",
      " [ 82   4   0  23  27   7 256   9]\n",
      " [ 54   2   0  34  25   4  13 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ausland       0.62      0.88      0.73       738\n",
      "      Kultur       0.84      0.39      0.53       224\n",
      "    Netzwelt       0.89      0.16      0.27       100\n",
      "    Panorama       0.69      0.73      0.71       622\n",
      "     Politik       0.66      0.69      0.68       468\n",
      "       Sport       0.87      0.87      0.87       407\n",
      "  Wirtschaft       0.76      0.63      0.69       408\n",
      "Wissenschaft       0.78      0.50      0.61       263\n",
      "\n",
      "    accuracy                           0.70      3230\n",
      "   macro avg       0.76      0.61      0.64      3230\n",
      "weighted avg       0.73      0.70      0.69      3230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = titel_set\n",
    "\n",
    "x = np.array(data[\"Title\"])\n",
    "y = np.array(data[\"Category\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "X_train, X_validation, y_train, Y_validation = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_validation)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa22956",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9141e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(df):\n",
    "    columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "    le = LabelEncoder()\n",
    "    for feature in columnsToEncode:\n",
    "        try:\n",
    "            df[feature] = le.fit_transform(df[feature])\n",
    "        except:\n",
    "            print('Error encoding '+feature)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
